{% include header.html %}

# Projects


## HITar

Freedom of expression at your fingertips.

Messy pedalboards. Barely controllable digital sets. Many devices that do one thing, and can do one wrong thing. The life of the modern musician is filled with great technology, controlled with not-so-great interfaces. The HITar demonstrates a revolutionary technology to control loops, percussion, effects, and tech straight from your guitar's body, with the musicality and nuance that you expect from your guitar.

Imagine triggering a loop with a tap on the guitar's side. Imagine playing amazing drums alongside your song, all without missing a note. Stadium-ready performances coming just from your fingers and from your instrument. The HITar is all this, and much more.

### How does it work?

* Real-time AI tracking your percussive taps, 3 years of R&D
* Works from integrated contact pickups
* Bespoke embedded AI platform for ultra-low latency
* Built-in or retrofitted

### Accolades, press coverage

MIDI Innovation Awards 2023 -- Best hardware prototype

Guthman Musical Instrument Competition 2023 -- Third place

Exhibited at:
* NAMM 2024
* Music China 2023

Press coverage:
* Reuters
* Computer Times
* Rai TG Leonardo
* Sic Noticias
* The Economic Times

### ...it can be in [YOUR](https://www.linkedin.com/in/andrea-martelloni-7ab10a60) guitar.

I can build a HITar for you.
<br>
I can help you make HITar a reality for your product line.
<br>
I can bring my expertise into your company.


## MEML

**Bridging AI and Artistry in Real-Time Musical Performance.**

While AI and Machine Learning are transforming music creation, many advanced models create a disconnect, distancing the intuitive act of performance from the technology. GenAI and large models often reduce musical interaction to prompts and clicks, bypassing the rich, nuanced control of a musician playing an instrument.

**MEML (Musically Embodied Machine Learning)** directly addresses this challenge. Funded by UK AHRC, our project isn't just about applying AI to music; it's about **embedding intelligent systems directly *within* musical instruments.** We empower performers by making AI an integral, controllable part of their live expression, allowing the instrument to learn and respond to their unique playing style in real-time.

**Our Approach & Technical Innovation:**
*   **Problem-Driven Solution:** We identified the growing gap between powerful AI and expressive musical control, and engineered a solution to bridge it.
*   **Custom Embedded AI/ML:** We developed a bespoke C++ framework for ML training and inference, optimized for ultra-low latency and real-time operation on resource-constrained embedded platforms. This demonstrates expertise in creating efficient, from-scratch solutions for resource-constrained environments.
*   **Interactive Reinforcement Learning:** We leverage reinforcement learning paradigms enabling AI models to be trained and adapted *during* the performance. This showcases practical application of advanced ML in dynamic, human-in-the-loop systems.
*   **Open & Collaborative:** Our hardware and software are open-source, fostering innovation through artist collaborations and educational workshops.


### Members

[Chris Kiefer](https://www.linkedin.com/in/chris-kiefer-a2b46611a/), principal investigator
<br>
[Andrea Martelloni](https://www.linkedin.com/in/andrea-martelloni-7ab10a60), PDRF and software engineer

### The MEML framework

* [meMLP](https://github.com/MusicallyEmbodiedML/memlp) - An embedded-first C++ ML/AI training and inference library with first-class support for reinforcement learning
* [memllib](https://github.com/MusicallyEmbodiedML/memllib) - A library to get started with embedded AI development on the RP2350 (Raspberry Pi Pico 2)


### [Main website](https://users.sussex.ac.uk/~ck84/meml/)
