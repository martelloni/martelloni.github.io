{% include header.html %}

# Projects


## HITar

Freedom of expression at your fingertips.

Messy pedalboards. Barely controllable digital sets. Many devices that do one thing, and can do one wrong thing. The life of the modern musician is filled with great technology, controlled with not-so-great interfaces. The HITar demonstrates a revolutionary technology to control loops, percussion, effects, and tech straight from your guitar's body, with the musicality and nuance that you expect from your guitar.

Imagine triggering a loop with a tap on the guitar's side. Imagine playing amazing drums alongside your song, all without missing a note. Stadium-ready performances coming just from your fingers and from your instrument. The HITar is all this, and much more.

### How does it work?

* Real-time AI tracking your percussive taps, 3 years of R&D
* Works from integrated contact pickups
* Bespoke embedded AI platform for ultra-low latency
* Built-in or retrofitted

### Accolades, press coverage

MIDI Innovation Awards 2023 -- Best hardware prototype

Guthman Musical Instrument Competition 2023 -- Third place

Exhibited at:
* NAMM 2024
* Music China 2023

Press coverage:
* Reuters
* Computer Times
* Rai TG Leonardo
* Sic Noticias
* The Economic Times

### ...it can be in [YOUR](https://www.linkedin.com/in/andrea-martelloni-7ab10a60) guitar.

I can build a HITar for you.
<br>
I can help you make HITar a reality for your product line.
<br>
I can bring my expertise into your company.


## MEML

AI and ML are revolutionising the way we make music; however, the more advanced AI models become, the more they get separated from the immediate and intuitive act of performing music. Large language models and GenAI increasingly give us the ability to "query" music through keyboard and mouse, side-stepping the subtle skills of musicians playing a musical instrument in the moment.

Musically Embodied Machine Learning (MEML) is a project funded by UK AHRC to explore how we can build ML that benefits human-in-the-loop musical performance. We build ML instruments where ML is *in* the instrument, and the performer directly controls every aspect of it through their performance. We leverage our own small embedded ML framework and reinforcement learning paradigms, to make training and controlling ML parts of the musical performance. Our hardware and software technology is open-source and freely replicable. We build our instruments through collaborations with artists; we host seminars and workshops for developers and students.

### Members

[Chris Kiefer](https://www.linkedin.com/in/chris-kiefer-a2b46611a/), principal investigator
<br>
[Andrea Martelloni](https://www.linkedin.com/in/andrea-martelloni-7ab10a60), PDRF and software engineer

### The MEML framework

* [meMLP](https://github.com/MusicallyEmbodiedML/memlp) - An embedded-first C++ ML/AI training and inference library with first-class support for reinforcement learning
* [memllib](https://github.com/MusicallyEmbodiedML/memllib) - A library to get started with embedded AI development on the RP2350 (Raspberry Pi Pico 2)


### Main website